{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating training and benchmarking datasets\n",
    "This notebook will guide you through the process of creating the physical property training and benchmarking datasets used in the development of the transferable double exponential force field (DE-FF).\n",
    "\n",
    "## Physical properties\n",
    "\n",
    "First, we start with the optimisation datasets pulled from thermoML on which the DE-FF was trained. The majority of the dataset can be found in the  `physical-data-sets/sage-train-v1.json` which is taken directly from the Sage training [repo](https://github.com/openforcefield/openff-sage), the [script](https://github.com/openforcefield/openff-sage/blob/main/data-set-curation/physical-property/optimizations/curate-training-set.py) to reproduce this dataset can also be found in the repo. \n",
    "\n",
    "To make the complete training set we need to extract pure water properties from thermoML and add them to the sage training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from openff.evaluator.datasets.curation.components import filtering, selection, thermoml\n",
    "from openff.evaluator.datasets.curation.components.selection import State, TargetState\n",
    "from openff.evaluator.datasets.curation.workflow import (\n",
    "    CurationWorkflow,\n",
    "    CurationWorkflowSchema,\n",
    ")\n",
    "from openff.evaluator.datasets import PhysicalPropertyDataSet\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a new directory to store generated datasets so as not to overwrite the refernce datasets provided in `physical-data-sets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ouput_folder = \"remade-data-sets\"\n",
    "os.makedirs(new_ouput_folder, exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load thermoML and filter it for pure water density data at ambient conditions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = CurationWorkflow.apply(\n",
    "        pandas.DataFrame(),\n",
    "        CurationWorkflowSchema(\n",
    "            component_schemas=[\n",
    "                thermoml.ImportThermoMLDataSchema(cache_file_name=\"physical-data-sets/thermol.csv\"),\n",
    "                filtering.FilterByNComponentsSchema(n_components=[1]),\n",
    "                filtering.FilterDuplicatesSchema(),\n",
    "                filtering.FilterByPropertyTypesSchema(property_types=[\"Density\"]),\n",
    "                filtering.FilterByTemperatureSchema(\n",
    "                    minimum_temperature=280.0, maximum_temperature=370\n",
    "                ),\n",
    "                filtering.FilterByPressureSchema(\n",
    "                    minimum_pressure=99.9, maximum_pressure=101.4\n",
    "                ),\n",
    "                filtering.FilterBySmilesSchema(smiles_to_include=[\"O\"]),\n",
    "                selection.SelectDataPointsSchema(\n",
    "                    target_states=[\n",
    "                        TargetState(\n",
    "                            property_types=[\n",
    "                                (\"Density\", 1),\n",
    "                            ],\n",
    "                            states=[\n",
    "                                State(\n",
    "                                    temperature=temperature,\n",
    "                                    pressure=101.325,\n",
    "                                    mole_fractions=(1.0,),\n",
    "                                )\n",
    "                                for temperature in [\n",
    "                                    281.15,\n",
    "                                    298.15,\n",
    "                                    313.15,\n",
    "                                    329.15,\n",
    "                                    345.15,\n",
    "                                    361.15,\n",
    "                                ]\n",
    "                            ],\n",
    "                        )\n",
    "                    ]\n",
    "                ),\n",
    "            ]\n",
    "        ),\n",
    "        n_processes=4,\n",
    "    )\n",
    "\n",
    "density_data = PhysicalPropertyDataSet.from_pandas(data_frame=data_frame)\n",
    "with open(os.path.join(new_ouput_folder, \"pure_water_rho.json\"), \"w\") as output:\n",
    "    output.write(density_data.json())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will produce a new pure water-only dataset at `remade-data-sets/pure_water_rho.json` which can be viewed as a table using the to pandas method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_data.to_pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create the fitting dataset by combining the pure water and  sage datasets. First, load the sage data and check the number of entries, we expect 1032 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sage_data = PhysicalPropertyDataSet.from_json(\"physical-data-sets/sage-train-v1.json\")\n",
    "sage_data.to_pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add in the water densities and make sure the number of rows has increased to 1038. Then save as an evaluator input file as `remade-data-sets/sage-and-water-rho.json` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sage_data.add_properties(*density_data.properties)\n",
    "sage_data.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(new_ouput_folder, \"sage_and_water_rho.json\"), \"w\") as output:\n",
    "    output.write(sage_data.json())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physical property benchmarks\n",
    "\n",
    "Here we will construct the benchmark hydration-free energy dataset by re-filtering the sage [set](https://github.com/openforcefield/openff-sage/blob/main/data-set-curation/physical-property/benchmarks/data-sets/sage-fsolv-test-v1.json) see the original filtering [script](https://github.com/openforcefield/openff-sage/blob/main/data-set-curation/physical-property/benchmarks/curate-fsolv-test-set.py) for details on its construction. This was done by creating a list of solutes for which we have an aqueous and non-aqueous solvation free energy measurement, the list of solutes is included in `pysical-data-sets/filtered-mnsol.txt`.\n",
    "\n",
    "The mnsol non-aqueous solvation free energy test set can be constructed filtering for records containing these same solutes, due to licensing issues a text file with IDs of the records used from MNsol is included at `pysical-data-sets/filtered-mnsol.txt`. See the original [instructions](https://github.com/openforcefield/openff-sage/blob/2.0.0-rc.1/data-set-curation/physical-property/benchmarks/README.md) on downloading the MNsol dataset and processing it into a CSV format compatible with the openff-evaluator filtering tools. This dataset should then be filtered for the substances in `pysical-data-sets/filtered-mnsol.txt` to create the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the sage dataset and all of the unique solutes from the processed mnsol dataset\n",
    "sage_fsolv = PhysicalPropertyDataSet.from_json(\"physical-data-sets/sage-fsolv-test-v1.json\")\n",
    "solutes = set()\n",
    "with open(\"physical-data-sets/filtered-mnsol.txt\") as mnsol:\n",
    "    for line in mnsol.readlines():\n",
    "        if \"Id\" in line:\n",
    "            continue\n",
    "        data = line.split(\",\")\n",
    "        solute = data[1] if data[2] == \"Solute\" else data[3]\n",
    "        solutes.add(solute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in 3 missing solutes which were used to expand the hydration free energy test set\n",
    "for mol in [\"CCCO\", \"CCCCO\", \"Cc1ccc(O)cc1\"]:\n",
    "    solutes.add(mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any records that are not with a solute we want\n",
    "entries_to_keep = []\n",
    "for entry in sage_fsolv.properties:\n",
    "    solute = [component.smiles for component in entry.substance.components if component.role.name == \"Solute\"][0]\n",
    "    if solute in solutes:\n",
    "        entries_to_keep.append(entry)\n",
    "# we should have 72 entries\n",
    "len(entries_to_keep)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an evaluator dataset for the hydration-free energies from the entries we want to keep and save it to `remade-data-sets/fsolv-filtered.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sage_fsolv._properties = entries_to_keep\n",
    "with open(\"remade-data-sets/fsolv-filtered.json\", \"w\") as output:\n",
    "    output.write(sage_fsolv.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dexp_old",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
