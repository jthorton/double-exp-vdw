#!/usr/bin/env bash
#SBATCH -J benchmark_parallel
#SBATCH -p standard
#SBATCH -t 08:00:00
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=1
#SBATCH --mem-per-cpu=8gb
#SBATCH --array=1-497
#SBATCH --account dmobley_lab
#SBATCH --export ALL
#SBATCH --requeue

# Set the output and error output paths.
#SBATCH -o  ./slurm_output/slurm-%J.out
#SBATCH -e  ./slurm_output/slurm-%J.err
#

mkdir -p 02-outputs
mkdir -p 03-outputs

. ~/.bashrc
# Use the right conda environment
conda activate /dfs6/pub/pbehara/bin/conda/smirnofee

#conda env export > conda_env.yaml

python /dfs4/dmobley-lab/pbehara/fitting-exp/df4_benchmark-data/02-b-minimize.py -i 02-chunks/01-processed-qm-"$SLURM_ARRAY_TASK_ID".sdf -ff openff_unconstrained-2.0.0.offxml -o 02-outputs/openff-2-0-0-"$SLURM_ARRAY_TASK_ID".sdf


python /dfs4/dmobley-lab/pbehara/fitting-exp/df4_benchmark-data/02-b-minimize.py -i 02-chunks/01-processed-qm-"$SLURM_ARRAY_TASK_ID".sdf -ff /dfs6/pub/pbehara/fitting-exp-dfs6/dexp-valence-fit/reduced-set-targets/result/optimize/force-field.offxml -o 02-outputs/iter-dexp-"$SLURM_ARRAY_TASK_ID".sdf

python /dfs4/dmobley-lab/pbehara/fitting-exp/df4_benchmark-data/02-b-minimize.py -i 02-chunks/01-processed-qm-"$SLURM_ARRAY_TASK_ID".sdf -ff /dfs6/pub/pbehara/fitting-exp-dfs6/dexp-valence-fit-sage/reduced-set-targets/result/optimize/force-field.offxml -o 02-outputs/iter-sage-retrained-"$SLURM_ARRAY_TASK_ID".sdf

python /dfs4/dmobley-lab/pbehara/fitting-exp/df4_benchmark-data/03-a-compute-metrics.py --input "03-force-fields.json" --index "$SLURM_ARRAY_TASK_ID" --output 03-outputs/03-metrics-"$SLURM_ARRAY_TASK_ID".csv

