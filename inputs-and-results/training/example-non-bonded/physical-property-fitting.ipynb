{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physical property fitting\n",
    "\n",
    "This notebook will guide you through the process of creating the physical property fitting folder structure required for ForceBalance and demonstrate the fitting of a small toy dataset using a local OpenFF-Evaluator server.\n",
    "\n",
    "The fitting of the full dataset is computationally demanding and required 60 GPUs and 6 days of wallclock time on an HPC cluster to complete. We recommend following the HPC guide in the OpenFF-Evaluator [documentation](https://docs.openforcefield.org/projects/evaluator/en/stable/backends/daskbackends.html#dask-hpc-cluster) to adapt the local Dask cluster to your needs.\n",
    "\n",
    "## Setting up the ForceBalance inputs\n",
    "\n",
    "First, we begin by creating the directory to store our initial force field parameters and another to store our dataset of targets physical properties which we will be fitting to:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openff.evaluator.datasets import PhysicalPropertyDataSet\n",
    "from openff.evaluator.datasets.curation.components.filtering import (\n",
    "    FilterBySmilesSchema,\n",
    "    FilterByMoleFractionSchema,\n",
    "    FilterByPropertyTypesSchema\n",
    ")\n",
    "from openff.evaluator.datasets.curation.workflow import CurationWorkflow, CurationWorkflowSchema\n",
    "\n",
    "os.makedirs(\"forcefield\", exist_ok=True)\n",
    "os.makedirs(os.path.join(\"targets\", \"phys-prop\"), exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can now move our fitting target dataset into the targets folder. In this example will be creating a simple toy dataset with one density and one enthalpy of mixing extracted from the full DE-FF fitting dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_ff_dataset = PhysicalPropertyDataSet.from_json(\"../../../data-set-curation/physical-property/physical-data-sets/sage-train-v1.json\")\n",
    "toy_dataset = CurationWorkflow.apply(\n",
    "    de_ff_dataset, \n",
    "    CurationWorkflowSchema(\n",
    "        component_schemas=[\n",
    "            FilterBySmilesSchema(smiles_to_include=[\"O\", \"OC1=NCCC1\"]), \n",
    "            FilterByMoleFractionSchema(mole_fraction_ranges={2: [[(0.4, 0.6)]]}),\n",
    "            FilterByPropertyTypesSchema(property_types=[\"Density\", \"EnthalpyOfMixing\"], n_components={\"Density\": [2], \"EnthalpyOfMixing\": [2]})\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "toy_dataset.to_pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we now write our toy dataset to the target folder, to run the full fiting use the de_ff_dataset object instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"targets\", \"phys-prop\", \"toy-dataset.json\"), \"w\") as output:\n",
    "    output.write(toy_dataset.json(os.path.join(\"targets\", \"phys-prop\", \"toy-dataset.json\")))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation options\n",
    "\n",
    "The next step is to create the Evaluator estimation options file, which controls simulation settings and construction of the objective function used in ForceBalance. We do this by specifying the weight of each of the target properties and a scale factor or denominator used to scale the error in our calculated property to a unitless value that can be combined in a multiobjective optimisation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forcebalance.evaluator_io import Evaluator_SMIRNOFF\n",
    "from openff.units import unit\n",
    "from openff.evaluator.client import RequestOptions\n",
    "\n",
    "options = Evaluator_SMIRNOFF.OptionsFile()\n",
    "# set the local path to our target dataset\n",
    "options.data_set_path = \"toy-dataset.json\"\n",
    "# set the weights of the target properties to be equal\n",
    "options.weights = {\"Density\": 1.0, \"EnthalpyOfMixing\": 1.0}\n",
    "# set the property scale factors\n",
    "options.denominators = {\"Density\": 0.05 * unit.grams / unit.millilitre,\"EnthalpyOfMixing\": 1.6 * unit.kilojoule / unit.mole,}\n",
    "# pick which calculation back ends to use, use with simulation only\n",
    "evaluator_options = RequestOptions()\n",
    "evaluator_options.calculation_layers = [\"SimulationLayer\"]\n",
    "options.estimation_options = evaluator_options\n",
    "# write the file to the targets folder\n",
    "with open(os.path.join(\"targets\", \"phys-prop\", \"options.json\"), \"w\") as output:\n",
    "    output.write(options.to_json())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting Force Field Parameters\n",
    "\n",
    "We need to construct a DE-FF from which we can run the parameter optimisation, we will use the included scripts to build a DE-FF with an optimised tip4p water model. From this we can optimise the non-bonded parameters of the non-water types to the target data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the script to build our initial ff\n",
    "! python ../../../scripts/build_initial_ff.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load up the force field and type the molecules on which we will train to get a list of parameters to optimise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openff.toolkit.typing.engines.smirnoff import ForceField\n",
    "from openff.toolkit.topology import Molecule\n",
    "\n",
    "de_ff = ForceField(\"double-exp-ff.offxml\", load_plugins=True, allow_cosmetic_attributes=True)\n",
    "# create a molecule object for our target molecule, skip water as we don't want to optimise the parameters again\n",
    "target_mol = Molecule.from_smiles(\"OC1=NCCC1\")\n",
    "# label the atoms with the non-bonded smirks types\n",
    "de_labels = de_ff.label_molecules(topology=target_mol.to_topology())[0][\"DoubleExponential\"]\n",
    "\n",
    "# make a list of smirks to target\n",
    "target_smirks = set()\n",
    "for parameter in de_labels.values():\n",
    "    target_smirks.add(parameter.smirks)\n",
    "\n",
    "# if using openmm <7.7 keep `[#1:1]-[#8]` fixed\n",
    "target_smirks.remove(\"[#1:1]-[#8]\")\n",
    "target_smirks\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a list of smirks non-bonded types that are exercised by this dataset we can tag them to let ForceBalance know which parameters need gradients for the optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_handler = de_ff.get_parameter_handler(\"DoubleExponential\")\n",
    "\n",
    "for smirks in target_smirks:\n",
    "    de_parameter = de_handler[smirks]\n",
    "    de_parameter.add_cosmetic_attribute(\"parameterize\", \"epsilon, r_min\")\n",
    "\n",
    "# and can write out the final forcefield to the directory\n",
    "de_ff.to_file(os.path.join( \"forcefield\", \"force-field.offxml\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluator Server\n",
    "\n",
    "With the ForceBalance inputs created, we can now start our OpenFF-Evaluator server to which ForceBalance will send its estimation requests, for more information on how this works see the second evaluator [tutorial](https://docs.openforcefield.org/projects/evaluator/en/stable/tutorials/tutorial02.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the calculation backend which will distribute any calculations.\n",
    "from openff.evaluator.backends import ComputeResources\n",
    "from openff.evaluator.backends.dask import DaskLocalCluster\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "calculation_backend = DaskLocalCluster(\n",
    "    number_of_workers=1,\n",
    "    resources_per_worker=ComputeResources(\n",
    "        number_of_threads=1,\n",
    "        number_of_gpus=1,\n",
    "        preferred_gpu_toolkit=ComputeResources.GPUToolkit.CUDA,\n",
    "    ),\n",
    ")\n",
    "calculation_backend.start()\n",
    "\n",
    "# Launch the server object which will listen for estimation requests and schedule any\n",
    "# required calculations.\n",
    "from openff.evaluator.server import EvaluatorServer\n",
    "\n",
    "evaluator_server = EvaluatorServer(calculation_backend=calculation_backend)\n",
    "evaluator_server.start(asynchronous=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run ForceBalance \n",
    "\n",
    "With everything created and our Evaluator server ready and waiting for requests, we can start the optimisation with a single command. Note the ForceBalance control file is provided with the example, for more information on the options available see the ForceBalance [documentation](http://leeping.github.io/forcebalance/doc/ForceBalance-Manual.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ForceBalance optimize.in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dexp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
